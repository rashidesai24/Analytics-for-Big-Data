{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63BaYEpnVYCX",
        "colab_type": "text"
      },
      "source": [
        "**Mapper and Reducer with MapReduce**\n",
        "\n",
        "The Python file mimics the process of MapReduce task, specifically writing map and reduce functions (without distributing to several machines) to mimic the process of mapper and reducer. The task is to count the number of occurrences of each word in a text file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25tQmgTMISSh",
        "colab_type": "text"
      },
      "source": [
        "**Reading the file**\n",
        "\n",
        "The input here is a text document (around 13,000 lines) which includes several paragraphs. It is a raw data which requires some data cleaning works to prepare it for next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvlJCdKmHWy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2e4b17-b007-4128-d5df-d98a42cd01b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiWraY0dHda7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputfile = open('/content/drive/My Drive/MIS/Fall 2020/IDS 561 Big data/Pride_and_Prejudice.txt',\"r\")\n",
        "text = inputfile.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Ga65r4IrQz",
        "colab_type": "text"
      },
      "source": [
        "**Data Cleaning Function**\n",
        "\n",
        "This step includes data cleaning tasks such as removing numbers from text, punctuations and special symbols, uppercase to lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxf4m58jHdei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_clean(text):\n",
        "  RemoveNumbers = ''.join([i for i in text if not i.isdigit()]) # Removing the numbers from text\n",
        "  RemoveNumbers = text.lower()                                  # Changing case of text to lower case\n",
        "  import re\n",
        "  onlyText = re.sub(r\"[^a-z\\s]+\",' ',RemoveNumbers)             # Removing punctuation marks from text\n",
        "  finaltext = \"\".join([s for s in onlyText.strip().splitlines(True) if s.strip()]) # Removing all null lines\n",
        "  return finaltext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlyYPD35JA0D",
        "colab_type": "text"
      },
      "source": [
        "**Data Spilt Function**\n",
        "\n",
        "Output of data cleaning function fed into the data split function with two parts to output two separated subsets: Part1 (first 5000 lines of 13000) and Part2 (5001 and beyond lines)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOEpEaUfHdi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitlines(text,a):\n",
        "  linessplit = text.splitlines()   # Splitting the lines into a list\n",
        "  part1 = linessplit[0:5000]       # Part1 includes the first 5000 lines of the text file\n",
        "  part2 = linessplit[50001:]       # Part2 includes the rest of the text: lines 5001 and beyond\n",
        "  return part1,part2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSND5lBCJVrC",
        "colab_type": "text"
      },
      "source": [
        "**Mapper Function**\n",
        "\n",
        "The mapper function produces a set of key-value pairs for Part1 and Part2 subsets respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyU7aMWLHdnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapper(text,out_queue):\n",
        "  keyvalue = []\n",
        "  for i in text:\n",
        "    wordssplit = i.split()\n",
        "    for j in wordssplit:\n",
        "      keyvalue.append([j,1])      # Appending every word in the line with 1 and storing it in [\"word\", 1] format in a nested list\n",
        "  out_queue.put(keyvalue)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3voc8BvJX5L",
        "colab_type": "text"
      },
      "source": [
        "**Sort Function**\n",
        "\n",
        "Sort by key of Part1 and Part2 together, with an ascending sort order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB49ovvsHdtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sortedlists(list1,list2):\n",
        "  out = list1 + list2             # Combining the two input lists into a single list\n",
        "  out.sort(key= lambda x :x[0])   # Sorting the lists based on the first element of the list \"word\"\n",
        "  return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDOex3ZnJeeN",
        "colab_type": "text"
      },
      "source": [
        "**Partition Function**\n",
        "\n",
        "The output of sort function is fed into the partition function to give two ascending ordered partitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_War9DfEHdwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def partition(sorted_list) :\n",
        " sort1out = []\n",
        " sort2out = []\n",
        " for i in sorted_list:\n",
        "    if i[0][0] < 'n':            # Partitioning the sorted word list into two separate lists \n",
        "      sort1out.append(i)         # All the words starting with letter “a” to “m” are sent to Reducer1, and the others (“n” to “z”) are sent to Reducer2.\n",
        "    else : sort2out.append(i)\n",
        " return sort1out,sort2out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgYogbs5Ji6v",
        "colab_type": "text"
      },
      "source": [
        "**Reducer Function**\n",
        "\n",
        "Collect all values belonging to the key and count the frequency of words for the two ordered partitions. The function output is word frequency of the ordered partitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QWTKpTJHdzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reducer(part_out1,out_queue) :\n",
        "  sum_reduced = []\n",
        "  count = 1\n",
        "  for i in range(0,len(part_out1)):\n",
        "    if i < len(part_out1)-1:\n",
        "      if part_out1[i] == part_out1[i+1]:\n",
        "       count = count+1                              #Counting the number of words\n",
        "      else : \n",
        "       sum_reduced.append([part_out1[i][0],count])  #Appending the word along with count to sum_reduced list as [\"word\",count]\n",
        "       count = 1 \n",
        "    else: sum_reduced.append(part_out1[i])          #Appending the last word to the output list    \n",
        "  out_queue.put(sum_reduced)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkStLp8jRwue",
        "colab_type": "text"
      },
      "source": [
        "**Using multi-thread function**\n",
        "\n",
        "Multithreading is defined as the ability of a processor to execute multiple threads concurrently. It takes two user inputs as arguments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtvRlLVnRzyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import threading\n",
        "import queue\n",
        "def multi_thread_function(func,map1_input,map2_input):  #func is the function to be used with two threads taking two inputs map1_input and map2_input\n",
        "  my_queue1 = queue.Queue()  # Using a queue to store the values of mapper output and use them in sort function\n",
        "  my_queue2 = queue.Queue()\n",
        "  t1 = threading.Thread(target=func, args=(map1_input,my_queue1)) \n",
        "  t2 = threading.Thread(target=func, args=(map2_input,my_queue2))  \n",
        "  t1.start()                 # Executing input1\n",
        "  t2.start()                 # Executing input2 to run simultaneously with input1\n",
        "  t1.join()                  # Waiting for input1 to be executed\n",
        "  t2.join()                  # Waiting for input2 to be executed\n",
        "  list1out = my_queue1.get() # Getting values from queue into a variable to return its value\n",
        "  list2out = my_queue2.get()\n",
        "  return list1out,list2out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpDuVHAxJuus",
        "colab_type": "text"
      },
      "source": [
        "**Main Function**\n",
        "\n",
        "Final result of word counting by wrapping all the steps together and combining the output of the two partitions together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGQmITH2Jt7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main_function(text):  \n",
        "  cleantext = data_clean(text)\n",
        "  linessplit = splitlines(cleantext,5000)\n",
        "  mapperout = multi_thread_function(mapper,linessplit[0],linessplit[1]) \n",
        "  sortedwords = sortedlists(mapperout[0],mapperout[1])\n",
        "  slicedwords = partition(sortedwords)\n",
        "  reducerout = multi_thread_function(reducer,slicedwords[0],slicedwords[1])\n",
        "  return reducerout[0]+reducerout[1]\n",
        "\n",
        "output = main_function(text)\n",
        "import pandas as pd\n",
        "pd.DataFrame(output).to_csv(\"Output.csv\",index=False,header = [\"Word\",\"Frequency\"]) # Saving file as a .csv file in the current directory"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}