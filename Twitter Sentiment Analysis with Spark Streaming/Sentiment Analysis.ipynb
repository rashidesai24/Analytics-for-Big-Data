{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conducting simple sentiment analysis by identifying positive or negative words using Bing Liu Opinion Lexicon.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SparkContext,and StreamingContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset containing the tweets, the same dataste which was outputted by the last cell of Twitter app.\n",
    "data = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"/Users/rashidesai/Downloads/streamoftweetsoutput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataset into rdd\n",
    "data_rdd = data.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the column name associated with the tweets\n",
    "data_rdd_tweet_only = data_rdd.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @SRuhle: There are some very large Trump donors who sit on hospital boards'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd_tweet_only.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the list of punctuations we will be removing before calculating the sentiment score\n",
    "punctuations = [\"(\", \"[\", \",\", \".\", \"!\", \"?\", \":\", \";\", \"]\", \")\", \"@\", \"^\",'#','&', 'Ä', \"Ä¶\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_punctuations(text):\n",
    "    for char in text:\n",
    "        if char in punctuations:\n",
    "          text = text.replace(char,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the punctuations and converting the entire tweet into lower case.\n",
    "clean = data_rdd_tweet_only.map(lambda text : eliminate_punctuations(text)).map(lambda text : text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt sruhle there are some very large trump donors who sit on hospital boards'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing text file containing the positive words\n",
    "positive = spark.sparkContext.textFile('/Users/rashidesai/Downloads/positive-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing text file containing the negative words\n",
    "negative = spark.sparkContext.textFile('/Users/rashidesai/Downloads/negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a key value pair rdd with key as the tweet and value as the words in the tweet.\n",
    "clean_pair = clean.map(lambda x : (x,x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rt sruhle there are some very large trump donors who sit on hospital boards',\n",
       " ['rt',\n",
       "  'sruhle',\n",
       "  'there',\n",
       "  'are',\n",
       "  'some',\n",
       "  'very',\n",
       "  'large',\n",
       "  'trump',\n",
       "  'donors',\n",
       "  'who',\n",
       "  'sit',\n",
       "  'on',\n",
       "  'hospital',\n",
       "  'boards'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pair.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting positive words in one list\n",
    "positive_list = positive.collect()\n",
    "# Extracting negative words in another list\n",
    "negative_list = negative.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(x):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for words in x:\n",
    "        if words in positive_list:\n",
    "            positive_count = positive_count + 1 \n",
    "        elif words in negative_list:\n",
    "            negative_count = negative_count + 1\n",
    "    return(positive_count - negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = clean_pair.map(lambda x : (x[0],sentiment_score(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the tweet and the sentiment score into the list.\n",
    "lis = ans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "# Converting list to Dataframe\n",
    "df = pd.DataFrame(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = (['Tweet_content','Sentiment Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the dataframe as a csv\n",
    "df.to_csv('/Users/rashidesai/Downloads/result.csv',encoding = 'utf-8',index = False) # Writing the final output to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atleast 1000 tweets are analysed for a sentiment score\n",
    "#### Twitter_Read.ipynb - The Tweet Listener code\n",
    "#### Spark_Demo.ipynb - Spark Streaming Application \n",
    "#### Sentiment_Analysis.ipynb - Report the sentiment score of each tweet \n",
    "#### result.csv - Output file with Tweet_content and Sentiment score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
